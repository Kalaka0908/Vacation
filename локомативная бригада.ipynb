{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "import random\n",
    "import pathlib\n",
    "import itertools\n",
    "import collections\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import remotezip as rz\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# Some modules to display an animation using imageio.\n",
    "import imageio\n",
    "from IPython import display\n",
    "from urllib import request\n",
    "from tensorflow_docs.vis import embed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture('/Users/kakotichi/Downloads/train_dataset_Бригады/Анализ бригад (телефон)/Есть телефон/00_51_01.mp4')\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Выполните обработку каждого кадра с использованием загруженной модели\n",
    "    # Например, используйте model.predict(frame) для определения объектов на кадре\n",
    "\n",
    "    # Отображение кадра\n",
    "    cv2.imshow('Video', frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import tarfile\n",
    "from urllib.request import urlretrieve\n",
    "\n",
    "\n",
    "def progress_bar(count, total, status=\"\"):\n",
    "    bar_len = 60\n",
    "    filled_len = int(round(bar_len * count / float(total)))\n",
    "\n",
    "    percents = round(100.0 * count / float(total), 1)\n",
    "    bar = \"=\" * filled_len + \"-\" * (bar_len - filled_len)\n",
    "\n",
    "    sys.stdout.write(\"[{}] {}%  {}\\r\".format(bar, percents, status))\n",
    "    sys.stdout.flush()\n",
    "\n",
    "\n",
    "def download_progress(block_num, block_size, total_size):\n",
    "    progress_bar(block_num * block_size, total_size)\n",
    "\n",
    "\n",
    "url = \"http://host.robots.ox.ac.uk/pascal/VOC/voc2012/VOCtrainval_11-May-2012.tar\"\n",
    "output_directory = \"./data\"\n",
    "output_file = os.path.join(output_directory, \"voc2012_raw.tar\")\n",
    "extract_directory = os.path.join(output_directory, \"voc2012_raw\")\n",
    "\n",
    "# Создание папок, если они не существуют\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "os.makedirs(extract_directory, exist_ok=True)\n",
    "\n",
    "# Загрузка архива\n",
    "urlretrieve(url, output_file, reporthook=download_progress)\n",
    "\n",
    "# Извлечение содержимого архива\n",
    "with tarfile.open(output_file, \"r\") as tar:\n",
    "    tar.extractall(path=extract_directory)\n",
    "\n",
    "# Вывод содержимого извлеченной папки\n",
    "for item in os.listdir(os.path.join(extract_directory, \"VOCdevkit/VOC2012\")):\n",
    "    print(item)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ImageSets====================================================] 100.0%  \n",
      "SegmentationClass\n",
      ".DS_Store\n",
      "SegmentationObject\n",
      "Annotations\n",
      "JPEGImages\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import tarfile\n",
    "from urllib.request import urlretrieve\n",
    "\n",
    "\n",
    "def progress_bar(count, total, status=\"\"):\n",
    "    bar_len = 60\n",
    "    filled_len = int(round(bar_len * count / float(total)))\n",
    "\n",
    "    percents = round(100.0 * count / float(total), 1)\n",
    "    bar = \"=\" * filled_len + \"-\" * (bar_len - filled_len)\n",
    "\n",
    "    sys.stdout.write(\"[{}] {}%  {}\\r\".format(bar, percents, status))\n",
    "    sys.stdout.flush()\n",
    "\n",
    "\n",
    "def download_progress(block_num, block_size, total_size):\n",
    "    progress_bar(block_num * block_size, total_size)\n",
    "\n",
    "\n",
    "url = \"http://host.robots.ox.ac.uk/pascal/VOC/voc2012/VOCtrainval_11-May-2012.tar\"\n",
    "output_directory = \"./data\"\n",
    "output_file = os.path.join(output_directory, \"voc2012_raw.tar\")\n",
    "extract_directory = os.path.join(output_directory, \"voc2012_raw\")\n",
    "\n",
    "# Создание папок, если они не существуют\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "os.makedirs(extract_directory, exist_ok=True)\n",
    "\n",
    "# Загрузка архива\n",
    "urlretrieve(url, output_file, reporthook=download_progress)\n",
    "\n",
    "# Извлечение содержимого архива\n",
    "with tarfile.open(output_file, \"r\") as tar:\n",
    "    tar.extractall(path=extract_directory)\n",
    "\n",
    "# Вывод содержимого извлеченной папки\n",
    "for item in os.listdir(os.path.join(extract_directory, \"VOCdevkit/VOC2012\")):\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "root = \"/Users/kakotichi/Documents/GitHub/sf_data_science/Vacation\"  # Замените '/some/directory' на ваш действительный путь к корневой папке\n",
    "data_root = os.path.join(root, \"pew_research_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "def load_file(file_path):\n",
    "    data = []\n",
    "    with open(file_path, encoding=\"utf-8\") as csvfile:\n",
    "        reader = csv.DictReader(csvfile)\n",
    "        for row in reader:\n",
    "            data.append(row)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = os.path.join(data_root, \"/Users/kakotichi/Documents/GitHub/sf_data_science/Vacation/submission.csv\")\n",
    "file_data = load_file(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://host.robots.ox.ac.uk/pascal/VOC/voc2012/VOCtrainval_11-May-2012.tar to /Users/kakotichi/Documents/GitHub/sf_data_science/Vacation/VOCtrainval_11-May-2012.tar\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1999639040/1999639040 [14:37<00:00, 2280018.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /Users/kakotichi/Documents/GitHub/sf_data_science/Vacation/VOCtrainval_11-May-2012.tar to /Users/kakotichi/Documents/GitHub/sf_data_science/Vacation\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from torchvision.datasets import VOCSegmentation\n",
    "from torchvision.transforms import Compose, RandomHorizontalFlip\n",
    "\n",
    "# Указываем дополнительные настройки, если это необходимо\n",
    "seg_root = \"/Users/kakotichi/Documents/GitHub/sf_data_science/Vacation\"  # Замените '/some/path' на ваш путь к корневому каталогу данных\n",
    "image_set = \"train\"\n",
    "transformations = Compose([RandomHorizontalFlip(0.5)])\n",
    "\n",
    "# Создание набора данных для сегментации\n",
    "seg_dataset = VOCSegmentation(seg_root, year=\"2012\", image_set=image_set, transforms=transformations, download=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: /Users/kakotichi/Documents/GitHub/sf_data_science/Vacation/VOCtrainval_11-May-2012.tar\n",
      "Extracting /Users/kakotichi/Documents/GitHub/sf_data_science/Vacation/VOCtrainval_11-May-2012.tar to /Users/kakotichi/Documents/GitHub/sf_data_science/Vacation\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from torchvision.datasets import VOCSegmentation\n",
    "from torchvision.transforms import Compose, RandomHorizontalFlip\n",
    "\n",
    "# Указываем дополнительные настройки, если это необходимо\n",
    "seg_root = \"/Users/kakotichi/Documents/GitHub/sf_data_science/Vacation\"  # Замените '/some/path' на ваш путь к корневому каталогу данных\n",
    "image_set = \"train\"\n",
    "transformations = Compose([RandomHorizontalFlip(0.5)])\n",
    "\n",
    "# Создание набора данных для сегментации\n",
    "seg_dataset = VOCSegmentation(seg_root, year=\"2012\", image_set=image_set, transforms=transformations, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: /Users/kakotichi/Documents/GitHub/sf_data_science/Vacation/VOCtrainval_11-May-2012.tar\n",
      "Extracting /Users/kakotichi/Documents/GitHub/sf_data_science/Vacation/VOCtrainval_11-May-2012.tar to /Users/kakotichi/Documents/GitHub/sf_data_science/Vacation\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from torchvision.datasets import VOCDetection\n",
    "from torchvision.transforms import Compose, RandomHorizontalFlip\n",
    "\n",
    "# Указываем дополнительные настройки, если это необходимо\n",
    "det_root = \"/Users/kakotichi/Documents/GitHub/sf_data_science/Vacation\"  # Замените '/some/path' на ваш путь к корневому каталогу данных\n",
    "image_set = \"train\"\n",
    "transformations = Compose([RandomHorizontalFlip(0.5)])\n",
    "\n",
    "# Создание набора данных для обнаружения объектов\n",
    "det_dataset = VOCDetection(det_root, year=\"2012\", image_set=image_set, transforms=transformations, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: path/to/seg_data/VOCtrainval_11-May-2012.tar\n",
      "Extracting path/to/seg_data/VOCtrainval_11-May-2012.tar to path/to/seg_data\n",
      "Using downloaded and verified file: path/to/det_data/VOCtrainval_11-May-2012.tar\n",
      "Extracting path/to/det_data/VOCtrainval_11-May-2012.tar to path/to/det_data\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision.datasets import VOCSegmentation, VOCDetection\n",
    "\n",
    "class CombinedVOC(Dataset):\n",
    "    def __init__(self, seg_root, det_root, year, image_set, transforms=None, download=True):\n",
    "        self.seg_dataset = VOCSegmentation(seg_root, year=year, image_set=image_set, transforms=transforms, download=download)\n",
    "        self.det_dataset = VOCDetection(det_root, year=year, image_set=image_set, transforms=transforms, download=download)\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __len__(self):\n",
    "        return min(len(self.seg_dataset), len(self.det_dataset))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        seg_data, seg_target = self.seg_dataset[idx]\n",
    "        det_data, det_target = self.det_dataset[idx]\n",
    "\n",
    "        if self.transforms is not None:\n",
    "            seg_data, seg_target = self.transforms(seg_data, seg_target)\n",
    "            det_data, det_target = self.transforms(det_data, det_target)\n",
    "\n",
    "        return (seg_data, seg_target), (det_data, det_target)\n",
    "\n",
    "seg_root = \"path/to/seg_data\"\n",
    "det_root = \"path/to/det_data\"\n",
    "year = \"2012\"\n",
    "image_set = \"trainval\"\n",
    "transformations = None\n",
    "download = True\n",
    "\n",
    "combined_dataset = CombinedVOC(seg_root, det_root, year, image_set, transforms=transformations, download=download)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import urllib.request\n",
    "\n",
    "# Загрузка модели и весов YOLOv3\n",
    "yolo_config = \"/Users/kakotichi/Documents/GitHub/sf_data_science/Vacation/yolov3.cfg\"\n",
    "yolo_weights = \"/Users/kakotichi/Documents/GitHub/sf_data_science/Vacation/yolov3.weights\"\n",
    "net = cv2.dnn.readNet(yolo_weights, yolo_config)\n",
    "\n",
    "# Загрузка списка классов\n",
    "class_file = \"/Users/kakotichi/Documents/GitHub/sf_data_science/Vacation/coco.txt\"\n",
    "with open(class_file, 'r') as f:\n",
    "    classes = [line.strip() for line in f.readlines()]\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Получение выходных слоев для сети YOLO\n",
    "layer_names = net.getLayerNames()\n",
    "output_layers_indices = net.getUnconnectedOutLayers()\n",
    "output_layers_indices = np.reshape(output_layers_indices, (output_layers_indices.size,))\n",
    "out_layers = [layer_names[i - 1] for i in output_layers_indices]\n",
    "\n",
    "# Устанавливаем классы, которые хотим обнаружить\n",
    "classes_to_look_for = [\"person\", \"cell phone\", \"laptop\", \"tv\", \"remote\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "def detect_objects(frame, net, out_layers, classes_to_look_for):\n",
    "    height, width, channels = frame.shape\n",
    "    blob = cv2.dnn.blobFromImage(frame, scalefactor=1/255, size=(416, 416), mean=(0, 0, 0), swapRB=True, crop=False)\n",
    "    net.setInput(blob)\n",
    "    layer_outputs = net.forward(out_layers)\n",
    "\n",
    "    class_ids = []\n",
    "    confidences = []\n",
    "    boxes = []\n",
    "\n",
    "    for output in layer_outputs:\n",
    "        for detection in output:\n",
    "            scores = detection[5:]\n",
    "            class_id = np.argmax(scores)\n",
    "            confidence = scores[class_id]\n",
    "\n",
    "            if confidence > 0.4 and classes[class_id] in classes_to_look_for:\n",
    "                center_x = int(detection[0] * width)\n",
    "                center_y = int(detection[1] * height)\n",
    "                w = int(detection[2] * width)\n",
    "                h = int(detection[3] * height)\n",
    "\n",
    "                x = int(center_x - w / 2)\n",
    "                y = int(center_y - h / 2)\n",
    "\n",
    "                confidences.append(float(confidence))\n",
    "                boxes.append([x, y, w, h])\n",
    "                class_ids.append(class_id)\n",
    "\n",
    "    indices = cv2.dnn.NMSBoxes(boxes, confidences, score_threshold=0.4, nms_threshold=0.5)\n",
    "    \n",
    "    if isinstance(indices, tuple) and not indices:\n",
    "         indices = []\n",
    "    elif isinstance(indices, np.ndarray):\n",
    "        indices = indices.astype(int)\n",
    "        indices = indices.reshape(-1, 1).tolist()\n",
    "    else:\n",
    "        raise ValueError(f\"Unexpected value in 'indices': {indices}\")\n",
    "\n",
    "    for i in indices:\n",
    "        i = i[0]\n",
    "        x, y, w, h = boxes[i]\n",
    "        label = str(classes[class_ids[i]])\n",
    "        detected_objects.append(label)\n",
    "        confidence = round(confidences[i], 2)\n",
    "        cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "        cv2.putText(frame, f'{label} {confidence}', (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)  \n",
    "    return frame, detected_objects\n",
    "yolo_config = \"/Users/kakotichi/Documents/GitHub/sf_data_science/Vacation/yolov3.cfg\"\n",
    "yolo_weights = \"/Users/kakotichi/Documents/GitHub/sf_data_science/Vacation/yolov3.weights\"\n",
    "net = cv2.dnn.readNet(yolo_weights, yolo_config)\n",
    "\n",
    "class_file = \"/Users/kakotichi/Documents/GitHub/sf_data_science/Vacation/coco.txt\"\n",
    "with open(class_file, 'r') as f:\n",
    "    classes = [line.strip() for line in f.readlines()]\n",
    "\n",
    "layer_names = net.getLayerNames()\n",
    "output_layers_indices = net.getUnconnectedOutLayers()\n",
    "output_layers_indices = np.reshape(output_layers_indices, (output_layers_indices.size,))\n",
    "out_layers = [layer_names[i - 1] for i in output_layers_indices]\n",
    "\n",
    "classes_to_look_for = [\"person\", \"cell phone\", \"laptop\", \"tv\", \"remote\"]\n",
    "\n",
    "video_path = \"/Users/kakotichi/Downloads/train_dataset_Бригады/Анализ бригад (телефон)/Есть телефон/00_26_30.mp4\"\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "\n",
    "\n",
    "class_file = \"/Users/kakotichi/Documents/GitHub/sf_data_science/Vacation/coco.txt\"\n",
    "with open(class_file, 'r') as f:\n",
    "    classes = [line.strip() for line in f.readlines()]\n",
    "\n",
    "\n",
    "output_folder = \"/Users/kakotichi/Documents/GitHub/sf_data_science/Vacation/result\"\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "output_video_path = os.path.join(output_folder, 'результат.mp4')\n",
    "\n",
    "out = cv2.VideoWriter(output_video_path, fourcc, 20.0, (frame_width,frame_height))\n",
    "\n",
    "phone_in_hands = False\n",
    "phone_detection_timer = None\n",
    "phone_hold_time = 3.0\n",
    "\n",
    "events = []  # список для сохранения всех событий\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if ret:\n",
    "        processed_frame, detected_objects = detect_objects(frame, net, out_layers, classes_to_look_for)\n",
    "        detected_objects_count = Counter(detected_objects)\n",
    "\n",
    "        detected_phone_count = detected_objects_count.get('cell phone', 0)\n",
    "        detected_person_count = detected_objects_count.get('person', 0)\n",
    "\n",
    "        if detected_phone_count > 0:\n",
    "            if not phone_in_hands:\n",
    "                phone_detection_timer = time.time()\n",
    "            phone_in_hands = True\n",
    "        else:\n",
    "            phone_in_hands = False\n",
    "        \n",
    "        if detected_person_count >= 2:\n",
    "            if phone_in_hands and (time.time() - phone_detection_timer) >= phone_hold_time:\n",
    "                event_msg = f\"Телефон(ы) был(и) в руках двух человек более {phone_hold_time} секунд.\"\n",
    "                events.append(event_msg)\n",
    "        elif detected_person_count == 1:\n",
    "            if phone_in_hands and (time.time() - phone_detection_timer) >= phone_hold_time:\n",
    "                event_msg = \"Телефон был в руках одного человека более 3-х секунд.\"\n",
    "                events.append(event_msg)\n",
    "       \n",
    "        cv2.imshow('Detected Objects', processed_frame)\n",
    "        out.write(processed_frame)\n",
    "\n",
    "        if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Вывод всех событий после завершения обработки видео\n",
    "print(\"\\nОбработка видео завершена. Обнаруженные события:\")\n",
    "for idx, event in enumerate(events, start=1):\n",
    "    print(f\"{idx}. {event}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
